{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Anaconda\\lib\\site-packages\\torchvision\\io\\image.py:11: UserWarning: Failed to load image Python extension: Could not find module 'C:\\Anaconda\\Lib\\site-packages\\torchvision\\image.pyd' (or one of its dependencies). Try using the full path with constructor syntax.\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as datasets\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data handling\n",
    "TRAIN_DIR = './data_map_cutouts/train4' #'../data__map_cutouts/train_v3'\n",
    "BATCH_SIZE = 32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_tensor = transforms.ToTensor()\n",
    "random_flips_v = transforms.RandomVerticalFlip(0.5)\n",
    "random_flips_h = transforms.RandomHorizontalFlip(0.5)\n",
    "to_grayscale = transforms.Grayscale(1)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    to_grayscale,\n",
    "    to_tensor,\n",
    "    random_flips_h,\n",
    "    random_flips_v\n",
    "])\n",
    "\n",
    "train_dir = pathlib.Path(TRAIN_DIR)  \n",
    "train_data = datasets.ImageFolder(root      = train_dir, \n",
    "                                  transform = transform)\n",
    "train_dataLoader = DataLoader(dataset = train_data,\n",
    "                     batch_size = BATCH_SIZE, \n",
    "                     shuffle    = True,\n",
    "                     drop_last  = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 128, 128])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x21bf7e09100>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQEAAAD7CAYAAABqkiE2AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAtrElEQVR4nO2da6xsSXXff+v0u8/r3svAcM2MGJAmOATFsYUcP6JoZOwY28ijfADhxNEkJhpFcmzsODIz8QeUD5FGsWWZD3noyi8cI2CESUCWY0MmQVakgM3Yjg2MxwyGwMCdBzP3cU53736dyofuVXd1nd3n1b27+5xeP6nV3bsfu7p31b9WrbWqSkIIOI6zvmwsuwCO4ywXFwHHWXNcBBxnzXERcJw1x0XAcdYcFwHHWXMKEwEReauIPC0iz4jII0Wdx3Gc2ZAi8gREpAT8FfADwLPAHwM/FkL4wtxP5jjOTJQL+t7vBJ4JIfw1gIh8CHgQyBUBEfGMJedcISJsbGywsbGBiFCr1SiXy1SrVSqVCtVqlWq1SqlUolwuIyKICCEEQggMBgOGwyHdbpder8dgMKDb7TIYDOj3+xwcHBBCiPdz6qy/GUJ4ZXqwKBF4DfA18/xZ4O/aN4jIw8DDBZ3fceaKiMTHpVKJSqVCo9GgXq9Tq9W49957uXLlCq997Wu5evUq99xzD/fddx/b29vcddddURR6vR69Xo+bN29y69Ytnn76aa5fv86LL77Il770JV566SWee+45er0enU6HdrtNv9+n3+/P42f8v7yDRYmA5BybkLIQwjXgGrgl4JxPtIfWnr3f79Pr9ciyjE6nQ6fToVwuk2UZw+GQg4MDut0u/X6fdrsdG3mWZVEcBoMBBwcHDIfDefX+x1KUCDwL3Gue3wN8o6BzOc7CUVNdG2y3240Nv9VqcevWLV566SWGwyGVSoVarUa1Wo3m/61bt3j55ZfZ29uj1WrR6XTIsiwOCYbDYRSCosWgKBH4Y+B+EXkd8HXgncA/KuhcjrMwdFxvBWA4HNLr9WIDz7KMdrvN3t4eAI1Gg263S71ej73+jRs3uHXrVrQE9LNqDagQLMIaKEQEQggDEfmXwB8AJeDXQwifL+JcjrMMVAiGwyGDwYAsyyiVSty6dSs6C0MINJtNOp0O1WqVer1Op9Oh2+1y48YN9vf3efHFF7l16xa3bt3i9u3bdDqdKATWGiiSoiwBQgi/B/xeUd/vOMvC+gJUCNQf0Ol0aDQatFotqtUqg8GAjY0NqtUqtVotWgJqBbRaLdrtNu12O9cncG4tAce56KgzEIgOP4AbN27E13q9HtVqldu3b1Mul6lUKrGht1otsizjpZdemvAL6LBArQANEaplUQQuAo5zCmxDVL+AiNDv9xEROp0OGxsb0UrQsGCpVKJUKkUzXx2BN2/ejILQ6/Xo9/sTArAIXAQcJ+Ekva4dCgDRKmi32xN+gmq1SrPZjElDKgLtdptut8vt27cnQoQqAlZgisZFwHFOiQqEvVczP4RAv9+n2+2yv79PqVSiVqtFS0B7eQ0Fag6B5hlYATjveQKOcy45bc+rFsFgMIjmPhCthI2NDfr9fkwxtqFF9Ruk4Ubb+NUfUCQuAo4zA9pgrRNPG73OGdCQYalUmpgPcHBwQL/fz/2ORS4A7CLgOIZpPe9RPbJtsNqQtcED0QpQK8E2+l6vN/HZPAE4t3kCjnNemdbojmqMqZ9APfsqHGoRWDS/YNm4CDjOHLA9uEYX0nsrIkXG/U+Li4DjzIHjrAQrCHrMRcBxLijp0CC1CNL3LRsXAccpmFVp7NPw1YYdZ0GkQ4BVEQcXAcdZc3w44DgLYhHzAM6CWwKOs+a4JeA4C2JVfAApbgk4zprjIuA4a46LgOOsOe4TcC401iOvW4HZ48fNDMxb3MNm/q3qOP80uAg4F568mXzp41QM7Oo+eZN9VmkC0Ky4CDhrgV3Ywy70ocdg0iqwq/+oIMDheQEXAReBc0zae12kijkPtJHbmy7wUS6Xc4VB/0NdLkxE4kIhuqjoRfufXQTOKXlj2otWOWfFNvxSqcTGxgaVSiXuKqyLf+prpVIp9vi6FdjGxkZc/MMKAlyc//vMIiAi9wK/BbwaOACuhRDeJyJXgA8D9wFfAd4RQrgxe1EdS96iFc4kVgB0yW9d+Vc3CLXHyuVynOSjuwe3Wq0oAPb+IjGLJTAAfi6E8Ccisg08KSKfBP4p8EQI4TEReQR4BHjP7EV1UlwAjiZ1COowoFKpUK/XqdfrcY9APa7OQN0WTNf+t+v/2e+9CP/9mUUghHAduD5+vCciTwGvAR4EHhi/7f3Ap3ARKIyLUAmLwDr9dBhgG//29jbb29vU63U2NzejJaBjf90SrFwu02q1Jr5THYUHBwdxGfHzzFx8AiJyH/DtwGeAu8cCQQjhuoi8aspnHgYensf5zzPTxvbeuGcndQiWSqW4MWij0aDZbFKv12k0GvE13SEIoFwuk2VZ3GvQ7h9wkYZjM4uAiGwBvwP8TAjh9kmnS4YQrgHXxt9xfv/BM2Dj03o/be05XZ/eORtqDdhhwNbWFru7u9ES2N7ejr6Bfr/PYDCgVqvFXYJKpRL9fj/uEaA7DakYnGcBgBlFQEQqjATgAyGEj44PPy8iV8dWwFXghVkLeRFIG3zaS1nxtLvQpKvVnvcKt2hSS6BWq03cms0mm5ubUSB0P0Bt5CoM1WqVSqUSIwZ2R6G1tQRkVGt/DXgqhPDL5qWPAw8Bj43vPzZTCc85eb29NnqtSHrMkqatWmvgPFe4ZaDWgLUI1CFYq9XifaPRoFwux63BgTh80EhCXrLRqi4WclJmsQS+F/gnwF+IyJ+Nj/0bRo3/cRF5F/BV4O0zlfAck1aStPHb1FXNWlOsJzrd4eai5a4XhW2oagmoAFghaDabVKtVNjc342dUCCqVCuVyOQpAmk+w1iIQQvjfwLRf/5azfu9FIjX7bS9i49f6Xvu5EMLE3nTAhTA9l81RDTZt2Mf19ue98SueMVgA01JUbU9Sq9Vib6TWQL/fj41e96lTh5QNT7lv4PTokEp3/tUdgbMso91ux6iAfV23Ctfn+r8vctvwReAiUBB5vUnqpa5WqzSbzdijaEXUyqffA8SKqIJhfQRuHeRj/Slp4+73+/R6PcrlMt1uNzpj9X1Zlk2IsKYRWxFepiBPs0LSDU9OgovAAlAB0PGleqVrtRrb29txSKAi0Ol0olWgF7vX68ULq2JgL7haCc4IbaQqAHrf7XapVqv0ej263S4iEsf8+r7BYECWZWRZRrfbnRAEFYJlbSMO+Zub6m8+S4fgIjBn8sJ/mq3WaDRihtrOzg71ep2dnZ1oLWjF2tvbo9frUalUaLfbdDqdmLOucevj5rs7xJ5dHX0ArVZrIhXY5gJUq9UJEej1ety8eZP9/X1arRa9Xm/CIlDrYdHiO+2cZ60DLgIFYiMAWsnUG725uUmj0YjZatqTa8XSCqcXXB+rAFwEr3TRWLNdzXzt/dvtNqVSKYpEqVSKcwX0fd1ul3a7HQXBCsCyfTPzPK+LwJxJQ4KVSiUmpmi++u7u7oQloA5DtQTUXFUzFYg9WZZludmFbgnkoz2mTQDSxpxlGZVKhWazGf01eg2yLIuzCHVIoL6D87a2gK0vebgIFEQan7bDApu/rpaA9koHBwcxGtDtdmMUQStoml0I56MiLgM7VNKGq9OA9T+sVCoMh8NDE4i057f+ABs9WOUITV6CmogwGAxy3+8iMEfyUoKtX0Anq6hfoNFoRMegVkYVgnK5HH0AWZbFyS022mBZ1Qq5bFQIbCq2DRHqf69inUYJut3uoaXGVlEApqWl2zwUF4ElYSuLtQy08ulNj6kAqPWg77cX1b7mzsHjseE863tRy2owGMRrow1cfTC9Xm8i0rCKOQJWAOySaSdNbXYRKIi8EI6SZg1qQpEN/9nUYv2+NA3WXvxVq5irhP1vtMHbtGx1DtqxszZ465zNm+G5TOz11/u0XtkOZBouAnMiNcMU66FWh5RNVMmyjHK5POF11jGoxrK73W4co9rKuOxKeB7Ia7TWGlBLACaFW4dl08z/Vfnv08xUzUCt1WrRolRBePnll3O/w0WgIPKEQMeVeq/j0tTcVF9AXvpqnlNqVSrkqnHc/2KHCHmvrar5D4dT09V5XK1WKZVKcUaknf04DReBBaGWQK/XiznrNpVYx/eDwYBOpxMz1jROba0BazV4luDJSEUzz5FmLYVlJQKdBDtctAuoVqtVGo1GDEdrBEp9Tk8++WTu97kIzAk700/vq9XqRLZap9NhY2MjqrP28HZdgRACe3t7dLtd9vb2aLfbMavNDgec2ZgmCnmvrwqp30LrjYaca7UaOzs7NBoNrly5EiNRah1Mw0VgjqRmujr5NDadZVk03USEWq1Gr9ebcOAA3L59myzL2NvbiwtepplqznxYlWSr40TImv/6ml09WddDuHTpEs1mk8uXL9NoNNja2oqrKU/DRaBAbOJPCKNlrG1CkCq4Om+0Iuzv79Pr9Wi1Wuzv78dFLtNJK6kZ66wH6axUzTzd3d3l7rvvptls8upXvzpmp25tbVGtVqd+n4tAgaShJnX0qUWgDkAb1wVot9v0+/1DwwA7TvWGv77YfBHNN9E5KZqAdunSJXZ3d3nFK17B7u4ulUpl6ve5CBSI9tg6LbjT6cSwn05gyYvjao9vQ4Uar04XIXXWD603aknqMODy5cu88pWv5PLly7z+9a/nrrvu4sqVK2xtbbkIrAJqDdiVg9KsLvteFQG74o1PGHLgcFKQ+gWsRbCzsxNnq25ubvpwYFmkY/Z+v39oKnAqAnZdgfTecYCJjECNDujiqbqpyubmJtvb22xtbcUdlqbhIrAgVAhsnnra+PXeTmI5KjvQrYH1JF1RSn0Eag1ouFCHC2opTMNFoEDyMvts3jrcafx2LkCaqHJUdqALwXpir3s6pyRNF7Z5KHm4CBRImnGWNnx9rLns6fuOa/AuAOuJXR8hnd9g56jYVHOfQLRETmLGa/ZX+roPAZxp2GGinZTW6/XodDp0Oh3a7Tb1ev3YnZNdBJZMmm6clymWvvc0rzsXD2sJ6MIn2vBv3ryJiPD8889PLJVWqE9ARErAZ4GvhxDeJiJXgA8D9wFfAd4RQrgx63kuOtMa8FENO3UqugisF2oFaN5JvV7n9u3bhBB47rnnYp5Jq9U6UgSmewtOzruBp8zzR4AnQgj3A0+MnzsFcdyCEc75wJr3R4m5fc3mk3Q6nZhmvre3x8svv8zzzz/P9evXeeGFF3jxxRenfuesW5PfA/wI8O+AfzU+/CDwwPjx+4FPAe+Z5TxOPr6wyPqQRpQ0IqD+JM1MBdja2qLf79NsNvnmN79Z+ASiXwF+Htg2x+4OIVwfF/y6iLwq74Mi8jDw8Iznd5y1I40E9Pt9yuUy7Xabvb29OI1d56YUNpVYRN4GvBBCeFJEHjjDD7kGXBt/l3dnjnNCbEhQ9z/QYcFwOGRvb48sy2IKca1WKyxP4HuBHxWRHwbqwI6I/DbwvIhcHVsBV4EXZjiH4zhHoEJg16zQZLNqtUqr1Tp2eTGZx5hybAn863F04BeBl0IIj4nII8CVEMLPH/N5twQc54Tk7WthpxXbzW916bqNjQ2++MUvPhlCeHP6fUXkCTwGPC4i7wK+Cry9gHM4ztqSdtw2x0RT06ctXZ/HXCyBWXFLwHFOT2oR6EQiO9XYCsDNmzcXZgk4jrMA0hBxupFKmkw2DRcBx7lA2Hkn6US1abgIOM4F47SrT7kIOM45Y9ry5MdNMJuGi4DjnENOutT8Sd7jIuA454x5zxmZxyxCx3HOMS4CjrPmuAg4zprjIuA4a46LgOOsOS4CjrPmuAg4zprjIuA4a46LgOOsOS4CjrPmuAg4zprjIuA4a46LgOOsOS4CjrPm+FTic8JRi0OcZFrptM+vwkKzymk3Vp33RqwnnaN/0XBL4Bxw3Oows76+Cpx0PTz7nnRBzVnPv66bu7olsAach97NLox5Hsp7kXAROAesS6OY9jvT3jldSlvNePv50/5np12c8yLhIuCsPLqZhj7Wxq/H7A48ep/eVoW84cayyzeTCIjIJeBXgTcBAfgJ4Gngw8B9wFeAd4QQbsxyHudk2Aq27Io1D2xj1/32jhu765bdIQQGg0GuMEyjiP9smhVjz7lsh+SsjsH3Ab8fQvhW4NuAp4BHgCdCCPcDT4yfO6fkLE6q0zjLrCm9ig4xu9mmCkC5XKZSqVCtVg/darVafKy78OZtxTVvh2JemY+62fed9fvnzZn3IhSRHeD/Aq8P5ktE5GngAbM1+adCCG845rvOf7c1Z84SLjtJGDH9vmlr2C8bbcS2MddqtYmddtPGNRwOGQ6H9Ho9hsMhg8GAg4MDDg4OolWgVoIyz9975KafJwjRHlWWOVl5c9+L8PXAi8BviMi3AU8C7wbuDiFcBxgLwavyPiwiDwMPz3B+Z8xJerbU5Ez3sNNjizJNjxK5dNttFYNKpRJvuvmm7eW18YcQ4nEVhhACw+Gw0N80TWCPui4bGxuHPnfc98z7+swiAmXgO4CfCiF8RkTexylM/xDCNeAauCWQclKTL89ZpvelUunQ+7Ux6O3g4OBQfH7RlkB6Tm34atJrr7+xsUGj0aBer7O5uRlfr1Qq8bNZltHtdtnf36ff79Pv9xkMBvT7/XiO1Im4iN+n9+l10uun5bLXxZY17zvnWf5ZROBZ4NkQwmfGzz/CSASeF5GrZjjwwqyFdA6TN95UxxkQe0LrQS+VShwcHEQxWPZQIK8yWwvANvRSqcTm5ibNZpOdnZ1oEZTLoyp8cHBAlmVkWQZAt9ul3W7H39Xv96c2qqJ+m70G1jeRWm36H1iL5eDg4JCVUJSldmYRCCE8JyJfE5E3hBCeBt4CfGF8ewh4bHz/sbmU1ImkFQw41Gvq66VSKVYaHSPbsbJWOPvdsPieUs9nBU0FoFarUalU2NnZYXNzk0uXLk04APXz3W6XbreLiNBut6OlE0KIArio32T9GXpvfRl5VsBgMIhbi+t1KdKHocyaJ/BTwAdEpAr8NfDPGEUcHheRdwFfBd4+4zkcQxont429Wq3mOtSAiR6m1+tFMYDpZuci0cZqBcA6BNUC2N7eZmdnJzoJ1fpRS6DT6TAcDimXy7RaregTsL6DosoPkxZYpVJhY2MjXhcVan1dTX8rxFYc0izKooR5JhEIIfwZcMjbyMgqcGbkpBODbPgsrWy2p1QLQB8DsYEseqyc/oZ0eGLNaLUG6vU61WqVer0eRUCdhHYcXavVGAwGlMtlBoPBoWFT6oOYx29Ox/rWMlMxsNdHLZPBYECpVDo0FND/YxGWmWcMGk4bhplT2Gbi+2yFttgeQtFG0Gg0oumszrOtra0JH4CGzIbDIfv7+/R6PTqdDjAaSnS73QnrwP6+IipgXnTCHtdG02w22draYnNzk0ajMfFccwNgJGbayHq9HiEEdnZ2YgMrl8vx3prZs1pBqQUgIrHx6/VpNpsT4qUCoeXu9/v0ej329vYYDAa0Wq14vW10I/3f5oWLwIzMq6GcJsachs+08tfrdZrNJpubm2xubkYrQAVAbzpW1sfARHbdoshzTlpsw7LDHM0VsI0JODSMsNGTIsjz/OvwRAWgUqlQr9ejgNlcBxhdm263S7/fn3jc6/WiYBU5jAEXgQmOq5SWvIY5j0Z0koQRrWRa0crlMvV6PY6ZtadUEVBrQCsXjKwIPVe3250QjGUNCew93HGYWRN6mpfdNnxrbh9FEb9TLYByuUytVqNWq3Hp0qVowdTr9XjNdFim4cxSqUS73WY4HE5cD2DCQps3LgIJ0yqGNcfz4vJ5s9hOY8JZ7/hRpGNO7WmazSaXLl1ie3ubRqPB9vZ2NEvVzM+yLCbUqNlsIwarEjZMhcA+VkGzY2kgDnVsvN1mCKbXY1qS0iy/1zppdWjWaDRiVENDnJr6rCKg+Q06pNFcB7XcNPkpjRTMCxeBE3LULDY47GG3lc9y3EWc9rodAmiPqOamOs103KwVTnsctQJUOLIsYzgcUqvV6Ha7Ew1KvdZFeqPT35vn79DXtCGnAqAN3jo47fjZCkAqJPa75/UbrWVih2k6DNDro0OCWq1GCCGa/eVyOVpp9Xo9Wgcq2tMcm/PAReAYVN1taCedlAJ3evC0wqaVch69jXU6qcMprWi7u7sxlq4Np1Kp0Ol0YgxdHWv9fj+OP62nOo9F5RHY8FmWZdFUBuJv6vV6VCqV6FVvt9t0Op1400akomGvRRG/IbXStLHXarUJcbYioOJcKpXIsowQAo1Gg16vR5Zl8brobwbmbhG4CByBVXYbiksdT/peIPZQ/X4/vjbNKlBOe0FTR1R6s74CDaEBEw61vKm5R4XSFoEVGPufDQYDut1ubBRZlrGxsRHNZyCa1TrkUQebFeUiPeyppWh9E3pNrFNTxUsbeOrvSP0eeT6TeeEiMAXb4+pFUXXXC2kvONyJxdvYu/bC885dT4VAy2QFQKfWakVU01/fp6+lXu6jWKQF0O/3ERFarRaDwYCNjY34GzqdThwOARNCsbe3FxOHsiyLYlD0ECcdDqTXRa+HDuHskEavixUPKwSQP9loHqy1CBxl2lo1tw1NzW87m802HO2J4I5VICJRDObRw9rxrJrCauraDDRtSFrRppnEec4z+z8syiKwZVIh7ff7saHrMAaIx/W1fr8fHWytVisKQq/XixOJFpEZmedYTX0bNinIDhvzrmGek3PerLUIQH4lt0qeOuKq1epEooq+BqMLrhVQL3Qal9f32fvToON2KwB5DjTtOeFOnoBWNFuZbMVMhaAIATjJd+pvUdHUNGe4EwXodrvR56HHVQTSIYEVxePOOytpowUONfY8v1F6PO+aFGXJrL0IQP50Vtvzl0ql6Ny5dOkSly9fpl6vU6/Xo2DoBVIRqNVqtNtt2u12HCZoJttZYvFpz60mZL/fjzPm2u12zDgUkZhEpJWt3W5PvFef22m3y8gTsOfTMKVNcdbnavJ3Op0oAFYEbMxd5xLkJUkVgX63HQKqQ3Nrawsg+jG0/OoY7HQ60YLR66LDGFv2olh7EVABsPfpuE4FQcM9agmoCGjPrJW2XC7HuK/N/LI5+mclz7zUiqKOM520otaA9bJ3u93oedbxtQ2lFek8O+o3pc9tL6ohTPsfqkVkp0qnFs8066eo32CtPxV9dWSWSiU6nc7E0FDfn1ovNqJRdLnBRQDgkADkxXt3dnbY2dlhd3eX3d3dmKNvRSCEQKVSIcuyWFG1p01XwZkF2/hLpVLsTW7cuDHRc6jzUiuTluXmzZu022329vaiEFgxWCapCOmQQE15HR7opBybWWfNfusrmfa75jncyTuHOjSr1Wr8n1Wo9dqEEGLDv3nzJq1WK1qTNpmrSNZeBI6Kh9thgXp07a3ZbMbXtWHq+FUXv9SEHDUXrcBMG+OlDsu8ntL2Ou12eyICoQ1GhUfLpmbn/v5+7HnSIYBtGEV70+3vmXbcip0tn4p2mu6chhatVZGeax4OWsXmiehraonZtQ1sdEbf3+v16PV6cXiWinKR/gBYcxHI+1Ptn61z2XX2l95r4oem5lar1VhZNazVbrdpNptxoQs7p10TP2wFtWWxjsb0ZgVCBUc95Tpm1kauIU3tEdvtNv1+n9u3b8dEGr3Z32ydU4v4z496byqER4UxU/Eqek3BvHLa5+oIVotLfUWaVpxGbfT62LUSF+EcXGsRyGNa7rw62dKEjjSpw/oSzmpunqQn1vGxppTqkECFQKfNqkDp2FNfTx1Oi+hxzoqKpR22TXufvV8k1tKzQxc7t8EOB3QIaaMDdsig4V11cur3eHSgAKwvQMnrbfLeM+2xTSDK46jElZP6DKxzUCuILqhphwM2IqEVymbSnRfyIgjTXs97vgimXQ87+UeHCFYE9FpoOFMFw75W5O9ZexFISStXGrO1Xmg19zY2NuJF0wtpTdJpzqm05z1pXr41N7V31HOrJdLtdifCl/q5tBw2RdUetz3vsskbEkwbyi0bG2mxQ0Sbb2I7FHtN8taAXIRl5iIwJi91dlrDt+Np64nW16ySp1l6acM/bWXO+5z2PNbZmGeRpGKjvZHGt48SquPKtUhWpRxHkQqu/r/pdcnrYI7K4CwCF4Ep2J5cc9VtDrg2PI0cWE+9zVyzySppIs5JL3DeECGtINo7avxcK1ye3yJdfUd/p7Vc1LrJE61V9BusGqkfAw6vQ5g6hfM6ibxh6byHcS4COVhzzmZ/aWNST7zG4tXbPxzeWb9vb28vhnymWQOzllHv04oWQphYdkuPpzPa7FAhL9nGZsDlecCdfNJrYp9bsU4/Y+8XiYtADtYKUIeNLsoJRBEIIcRGpe/V3W90brud0nrWxn8SHwHciRikn7EWgIandFYkECfqqBWhYU7rZFxUuO00nNSHsgymOSpnnaXp0YEFoH+y9oS9Xi/2mpoG3O/3qdVqbG9vRxHQHlSzxGxuvrUGjmpMeV7v05Zde5h0ApQmO5XLZba2tiYWwrSTdHT6raYWqxUEd9a5W8VGt6rMy+IrEheBMemfbb27cKcn1JCPHtcGplGBdAabisNJJ+ecNlKQ9/nUyakWgGYxNhqN+FiHBurstD4Em+U2r2nQ685J/r+iJjlNw0UgwZrWujpQmvKrq/O2Wq3oI9BeXsXAPtYogvbS87zI9rtUAKwVYNe+393dpdlscuXKlSgCOjRQwep0Ouzt7dFqtbhx40acB6ECoEMFpzhmtQhPy0wiICI/C/xzIAB/wWgbsibwYeA+4CvAO0IIN2Yq5RzJ62Gnjd/smNjmBKg1oD4BdRLa9QPSx3nht2k960krgO3x9T5d1cYuRmr3JKhWqzQajWgJaMjTon4Qm/asYcVVYFXKMW/S5LOVzRMQkdcAPw28MYTQEZHHgXcCbwSeCCE8JiKPMNqp+D1zKe0CSL20dk67poFaz7k2DDuDzebe28iAZdaLm5r8VgDSKdDa629ubsY9CXRDDLUEdPhiJ8Lowp46AUZ/21HZkM5spMJuHxcVQZh1OFAGGiLSZ2QBfAN4FHhg/Pr7gU+xQiIw7Q+cdlwbfNrbwp1prvY7bJKITc09zYU7yXvT8JM9v0V9AXZFYt0EQ6dD6/qDuqOvfk+tVovCkFonR82CtOTFufN+gzNiGf/JLFuTf11EfonRzsMd4BMhhE+IyN0hhOvj91wXkVflfV5EHgYePuv5F0ma+HHUBbIXcVHz89NkE+t7UMegLj5qFyPVJdLsbkS6gGe62OU0TuPAdF/CanJmu05ELgMPAq8DvgXYFJEfP+nnQwjXQghvDiHk7Wq8cuT18Dbxxx5bxuIcdkiQro2YN0RIk4bs6sr2cZrvrqJyUqxo5v1XbgUsn1mGA98PfDmE8CKAiHwU+B7geRG5OrYCrgIvzKGcS2ea+T3tfdNeXyR5Ds+0QaZDmDSz8ajvO+74ad/jLIdZPDxfBb5LRJoyahVvAZ4CPg48NH7PQ8DHZiviapDXYKY1pGX0cOlY0va46c06L+28hrzVbI5KGc7zFTjnj1l8Ap8RkY8AfwIMgD8FrgFbwOMi8i5GQvH2eRR01VjFnk39FnYSkC5WoZmAdudbIK51pyFC3cJLP2MTnmwEZJ7MmkrrzMZM0YEQwnuB9yaHu4ysAmcJpONuuyx5lmVxIVS4s422ioBu4GGXHUtXvp3XkuR5IbC83+IUj2cMXjCsCOiy19rIqtVqfK5bmqtJrw09yzLa7TatVov9/f24ZFlR+xH4cGL5uAjMyKrOZLNiYNewExH29/ep1WoToUR9j4pAp9M5tBrxSR2FR5FnARyVO7Bq/+tFxEXgjOQlwaxChU0blM5d0Ne0Z1dLQFGx0KGD9Qmksx9P+tvzGnnee/Iy4lbhv1wXXATOiPWQ2+fLxDaedM6DDgPsIqRZlh1Kj9YhhIqHXZX4qPChJW9Ow1H3Fptrob/JKRYXgRlZtUpqe1NNebZCoL26ioD9DNzZ9suKgI0MpO9XjjLzbW9vNxE5ahiQLpDqFIeLwAXD9tS2EWrj1rUQNPMvb5kruwS23udZAHk9ed7EJn2uGYt6zE5EshO10vyEopySzggXgQuKNfPzely7Fn6aBam9fl7yUN45FG3UVgDS2Y26kpFNP7ZpxOkGqU7xuAhccKwYqCDYxpX25ukcidP0wGnPLyJxglKtVouCUK1W44QmIA477BZcdiMOu+GrOw3nj4vABSc134/rYdP5Bemxk6C9vIhMLNOuyUk6e1G3SNNNW3U9Rx2u6MpO1h+R/iY9X95x52S4CKwRavanQwT7ut7PEq6zMxPT1Y10Y1dd6ESHAFmW0e/3abVaMaSpMx+73e5EeVYlHHtRcBG4wNgGc9LGM6tH3k5n1rUNK5UKOzs7NBoNtre3qdfrVCoVqtUqQExkyrIsWgWayqybdOr7AA8fzhkXgQvOIqf5pmsO6FCg0WjQbDZpNptsbW1Fn4AVAbt0u/oS1DmZ+gRUzDzleD64CKwRRfacaeNXc39nZ4fNzU3uuusuGo0Gm5ubcYHTer0eoxE6yxFGm7voTEf1E1gnZQh3dvp1ZsdFwJmZaSFBXd/Q3nRdQxUJIO7mBKNFTW30wOYV2PP5UGB+uAg4R3KUAzF9nzZYu5SZOgJ1teOdnZ1cx6AKh65sXKvV6PV6caqz9vzHzUNwcTg9LgLOqUkbW16uQV4YL40WVKvV+D49nq6DqJGGad+fzuFwITg9LgLOmRxsRwnBNEshXQjVbuAybVHUdFHTPAE4rmzO0bgIOCfiqEZlc/xhcptzXbFIH3c6nTibUb/TTl/WWYvpxKU0e9Eb+fxwEVgTTtPbn6WB2RCeXczUNmRNDdZMQDXzrVBo47drG6azHPPK58OCs+MisAYctZ7fPBuKFQC1BOyt1+uxv7/PcDikWq3GJKB+vx8XN82yLIYLdWu0vElM3sDnh4vAGrBIMzq1CHQH51u3bsVEIE0O0g1PNWOw1+vRarVotVpRFHRW4TwXOXUmcRFw5oI1v9U/oGsWanbfcDikUqnE/Q1tJqDOINzb26PdbpNlWRw+qCXhMwiLwUXAmZm8dQ03Njaiwy/dxzGNBujCJb1ej9u3b5NlWRQBtQSc4nARcGYincZrpyurXwCIk4J0erHmDCjqM1BfgH72pOsaOmfHRcCZmXRlIrtCEBAnBnU6Hfb29uIGp5VKJX6HNvYsy+JcAutkPK0AuGCcnGP3IhSRXxeRF0Tkc+bYFRH5pIh8cXx/2bz2qIg8IyJPi8gPFlVwZzVInY7WKWiXMddpwRoB0P0NdPyvNw0h2r0T887lzA857o8Vkb8P7AO/FUJ40/jYvwdeDiE8JiKPAJdDCO8RkTcCHwS+k9F25f8D+BshhCM3rxMRv7rnmGk5CJohaIcAmhuQbneu9VAdgNYCyAsNTvMT+CpDR/JkCOHN6cFjhwMhhD8UkfuSww8CD4wfvx/4FPCe8fEPhRC6wJdF5BlGgvB/zlxsZ+U5am6/NkZt0HbXo2lzDlQE8nwBJ10UxTk5Z/UJ3B1CuA4QQrguIq8aH38N8GnzvmfHxw4hIg8DD5/x/M6Kcdw8ArukuJIuOZ6+3z73xl0c83YM5nUHuVcvhHCN0VbmPhy4YORZBnlLnGnkwL4n7zH4xqVFclYReF5Ero6tgKvAC+PjzwL3mvfdA3xjlgI655e00dvj9j49Pu27nGI4NjowhY8DD40fPwR8zBx/p4jUROR1wP3AH81WROc8Yhu69fTbmx3zn6WR5/kVnNNzrCUgIh9k5AS8S0SeBd4LPAY8LiLvAr4KvB0ghPB5EXkc+AIwAH7yuMiAcz45zcrFxx1zlsuxIcKFFMJ9AucOD8WdS84WInScPLzxXxzO6hNwHOeC4CLgOGuOi4DjrDkuAo6z5rgIOM6a4yLgOGuOi4DjrDkuAo6z5rgIOM6a4yLgOGuOi4DjrDkuAo6z5rgIOM6a4yLgOGuOi4DjrDkuAo6z5rgIOM6a4yLgOGuOi4DjrDkuAo6z5rgIOM6a4yLgOGuOi4DjrDkuAo6z5hwrAiLy6yLygoh8zhz7RRH5SxH5cxH5ryJyybz2qIg8IyJPi8gPFlRux3HmxEksgd8E3poc+yTwphDC3wb+CngUQETeCLwT+Fvjz/xHESnNrbSO48ydY0UghPCHwMvJsU+EEHRz+U8z2oIc4EHgQyGEbgjhy8AzwHfOsbyO48yZefgEfgL47+PHrwG+Zl57dnzsECLysIh8VkQ+O4cyOI5zRmbakFREfoHRFuQf0EM5b8vduTKEcA24Nv4e393ScZbEmUVARB4C3ga8JdzZovZZ4F7ztnuAb5y9eI7jFM2ZhgMi8lbgPcCPhhDa5qWPA+8UkZqIvA64H/ij2YvpOE5RHGsJiMgHgQeAu0TkWeC9jKIBNeCTIgLw6RDCvwghfF5EHge+wGiY8JMhhGFRhXccZ3bkjiW/xEK4T8BxFsGTIYQ3pwc9Y9Bx1hwXAcdZc1wEHGfNcRFwnDXHRcBx1hwXAcdZc1wEHGfNmWnuwBz5JtAa3y+bu/ByWLwck5zncrw27+BKJAsBiMhn8xIZvBxeDi9HseXw4YDjrDkuAo6z5qySCFxbdgHGeDkm8XJMcuHKsTI+AcdxlsMqWQKO4ywBFwHHWXNWQgRE5K3jfQqeEZFHFnjee0Xkf4nIUyLyeRF59/j4FRH5pIh8cXx/eQFlKYnIn4rI7y6xDJdE5CPjPSWeEpHvXlI5fnZ8PT4nIh8UkfqiyjFln42p5y5qn41F7vexdBEY70vwH4AfAt4I/Nh4/4JFMAB+LoTwN4HvAn5yfO5HgCdCCPcDT4yfF827gafM82WU4X3A74cQvhX4tnF5FloOEXkN8NPAm0MIbwJKjPayWFQ5fpPD+2zknrvgfTbyylHMfh8hhKXegO8G/sA8fxR4dEll+RjwA8DTwNXxsavA0wWf9x5Glev7gN8dH1t0GXaALzN2Fpvjiy6HLlt/hVFG6+8C/2CR5QDuAz533H+Q1lXgD4DvLqocyWv/EPjAPMqxdEuAU+xVUCQich/w7cBngLtDCNcBxvevKvj0vwL8PHBgji26DK8HXgR+Yzws+VUR2Vx0OUIIXwd+CfgqcB24FUL4xKLLkTDt3Musu2fa7yOPVRCBE+9VUFgBRLaA3wF+JoRwe8HnfhvwQgjhyUWeN4cy8B3AfwohfDujuRwL888o4/H2g8DrgG8BNkXkxxddjhOylLo7y34feayCCCx1rwIRqTASgA+EED46Pvy8iFwdv34VeKHAInwv8KMi8hXgQ8D3ichvL7gMMLoOz4YQPjN+/hFGorDocnw/8OUQwoshhD7wUeB7llAOy7RzL7zumv0+/nEY2/6zlmMVROCPgftF5HUiUmXk4Pj4Ik4so/XSfw14KoTwy+aljwMPjR8/xMhXUAghhEdDCPeEEO5j9Nv/ZwjhxxdZhnE5ngO+JiJvGB96C6Ol4xdaDkbDgO8Skeb4+ryFkYNy0eWwTDv3QvfZKGy/jyKdPKdwgPwwI2/nl4BfWOB5/x4js+nPgT8b334YeAUjR90Xx/dXFlSeB7jjGFx4GYC/A3x2/H/8N+Dyksrxb4G/BD4H/BdGe1wspBzABxn5IvqMeth3HXVu4BfG9fZp4IcKLsczjMb+Wlf/8zzK4WnDjrPmrMJwwHGcJeIi4DhrjouA46w5LgKOs+a4CDjOmuMi4DhrjouA46w5/x90/UWUBx3+LAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "images, labels = next(iter(train_dataLoader))\n",
    "print(images.shape)\n",
    "plt.imshow(images[0, 0, :, :].detach().cpu().numpy(), cmap='Greys_r')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reshape(nn.Module):\n",
    "    def __init__(self, shape):\n",
    "        super(Reshape, self).__init__()\n",
    "        self.shape = shape\n",
    "        # print(shape)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.view(x.shape[0], *self.shape)\n",
    "    \n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, latent_dim) -> None:\n",
    "        super().__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.cuda = torch.cuda.is_available\n",
    "        self.device = torch.device(\"cuda\" if self.cuda else \"cpu\")\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels   = 1,\n",
    "                out_channels  = 64,\n",
    "                kernel_size   = 3,\n",
    "                stride        = 1,\n",
    "                padding       = 1\n",
    "            ),\n",
    "            nn.BatchNorm2d(num_features = 64,\n",
    "                           eps          = 0.01),\n",
    "            nn.ReLU(\n",
    "                # negative_slope=0.2,\n",
    "                inplace=True),\n",
    "            \n",
    "            nn.Conv2d(\n",
    "                in_channels   = 64,\n",
    "                out_channels  = 64,\n",
    "                kernel_size   = 3,\n",
    "                stride        = 1,\n",
    "                padding       = 1\n",
    "            ),\n",
    "            nn.BatchNorm2d(num_features = 64,\n",
    "                           eps          = 0.01),\n",
    "            nn.ReLU(\n",
    "                # negative_slope=0.2,\n",
    "                inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            \n",
    "            nn.Conv2d(\n",
    "                in_channels   = 64,\n",
    "                out_channels  = 128,\n",
    "                kernel_size   = 3,\n",
    "                stride        = 1,\n",
    "                padding       = 1\n",
    "            ),\n",
    "            nn.BatchNorm2d(num_features = 128,\n",
    "                           eps          = 0.01),\n",
    "            nn.ReLU(\n",
    "                # negative_slope=0.2,\n",
    "                inplace=True),\n",
    "            \n",
    "            nn.Conv2d(\n",
    "                in_channels   = 128,\n",
    "                out_channels  = 128,\n",
    "                kernel_size   = 3,\n",
    "                stride        = 1,\n",
    "                padding       = 1\n",
    "            ),\n",
    "            nn.BatchNorm2d(num_features = 128,\n",
    "                           eps          = 0.01),\n",
    "            nn.ReLU(\n",
    "                # negative_slope=0.2,\n",
    "                inplace=True),\n",
    "\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "\n",
    "            \n",
    "            nn.Conv2d(\n",
    "                in_channels   = 128,\n",
    "                out_channels  = 256,\n",
    "                kernel_size   = 3,\n",
    "                stride        = 1,\n",
    "                padding       = 1\n",
    "            ),\n",
    "            nn.BatchNorm2d(num_features = 256,\n",
    "                           eps          = 0.01),\n",
    "            nn.ReLU(\n",
    "                # negative_slope=0.2,\n",
    "                inplace=True),\n",
    "            \n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=256*32**2,\n",
    "                      out_features=latent_dim*2)\n",
    "\n",
    "        ).to(self.device)\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(in_features  = latent_dim, \n",
    "                      out_features = 256 * 32**2),\n",
    "            Reshape((256, 32, 32)),\n",
    "\n",
    "            nn.Conv2d(\n",
    "                in_channels   = 256,\n",
    "                out_channels  = 256,\n",
    "                kernel_size   = 3,\n",
    "                stride        = 1,\n",
    "                padding       = 1\n",
    "            ),\n",
    "            nn.BatchNorm2d(num_features = 256,\n",
    "                           eps          = 0.01),\n",
    "            nn.ReLU(\n",
    "                # negative_slope=0.2,\n",
    "                inplace=True),\n",
    "            \n",
    "            nn.ConvTranspose2d(\n",
    "                in_channels=256,\n",
    "                out_channels=128,\n",
    "                kernel_size=2,\n",
    "                stride=2,\n",
    "                padding=0\n",
    "            ),\n",
    "\n",
    "            nn.Conv2d(\n",
    "                in_channels   = 128,\n",
    "                out_channels  = 128,\n",
    "                kernel_size   = 3,\n",
    "                stride        = 1,\n",
    "                padding       = 1\n",
    "            ),\n",
    "            nn.BatchNorm2d(num_features = 128,\n",
    "                           eps          = 0.01),\n",
    "            nn.ReLU(\n",
    "                # negative_slope=0.2,\n",
    "                inplace=True),\n",
    "            nn.Conv2d(\n",
    "                in_channels   = 128,\n",
    "                out_channels  = 128,\n",
    "                kernel_size   = 3,\n",
    "                stride        = 1,\n",
    "                padding       = 1\n",
    "            ),\n",
    "            nn.BatchNorm2d(num_features = 128,\n",
    "                           eps          = 0.01),\n",
    "            nn.ReLU(\n",
    "                # negative_slope=0.2,\n",
    "                inplace=True),\n",
    "\n",
    "            nn.ConvTranspose2d(\n",
    "                in_channels=128,\n",
    "                out_channels=64,\n",
    "                kernel_size=2,\n",
    "                stride = 2,\n",
    "                padding=0\n",
    "            ),\n",
    "\n",
    "            nn.Conv2d(\n",
    "                in_channels   = 64,\n",
    "                out_channels  = 64,\n",
    "                kernel_size   = 3,\n",
    "                stride        = 1,\n",
    "                padding       = 1\n",
    "            ),\n",
    "            nn.BatchNorm2d(num_features = 64,\n",
    "                           eps          = 0.01),\n",
    "            nn.ReLU(\n",
    "                # negative_slope=0.2,\n",
    "                inplace=True),\n",
    "            nn.Conv2d(\n",
    "                in_channels   = 64,\n",
    "                out_channels  = 1,\n",
    "                kernel_size   = 3,\n",
    "                stride        = 1,\n",
    "                padding       = 1\n",
    "            ),\n",
    "            nn.BatchNorm2d(num_features = 1,\n",
    "                           eps          = 0.01),\n",
    "            nn.ReLU()           \n",
    "\n",
    "        ).to(self.device)\n",
    "\n",
    "        \n",
    "        self.encoder.apply(self._weights_init_normal).to(device=self.device)\n",
    "        self.decoder.apply(self._weights_init_normal).to(device=self.device)\n",
    "    \n",
    "    def _weights_init_normal(self, layer):\n",
    "        classname = layer.__class__.__name__\n",
    "        if classname.find(\"Conv\") != -1:\n",
    "            nn.init.normal_(layer.weight.data, 0.0, 1.)\n",
    "        elif classname.find(\"BatchNorm2d\") != -1:\n",
    "            nn.init.normal_(layer.weight.data, 1.0, 1.)\n",
    "            nn.init.constant_(layer.bias.data, 0.0)\n",
    "    \n",
    "    def encode(self, x):\n",
    "        mean = self.encoder(x)[:, :self.latent_dim]\n",
    "        logvar = self.encoder(x)[:, self.latent_dim:]\n",
    "\n",
    "        return mean, logvar\n",
    "    \n",
    "    def reparameterize(self, mean, logvar):\n",
    "        # eps ~ N(0,1)\n",
    "        eps = torch.normal(mean = 0, std=1, size=mean.shape, device=\"cuda\" if self.cuda else \"cpu\")\n",
    "        # returning ~ N(mean, exp^(logvar/2))\n",
    "        return eps * torch.exp(logvar * .5) + mean\n",
    "    \n",
    "    def decode(self, z, apply_sigmoid = False):\n",
    "        logits = self.decoder(z)\n",
    "        if apply_sigmoid:\n",
    "            probs = nn.Sigmoid()(logits).to(self.device)\n",
    "            return probs\n",
    "        return logits\n",
    "    \n",
    "    def sample(self, z=None):\n",
    "        if z is None:\n",
    "            z = torch.normal(mean = 0., std = 1., size=(BATCH_SIZE, self.latent_dim)).to(self.device)\n",
    "        return self.decode(z, apply_sigmoid=False)\n",
    "    \n",
    "    def log_normal_pdf(self, sample, mean, logvar, raxis=1):\n",
    "        # print(\"Logvar:\", type(logvar))\n",
    "        if type(logvar) == float and logvar == 0.:\n",
    "            logvar = torch.FloatTensor([0.]).to(self.device)\n",
    "        log2pi = np.log(2 * np.pi)\n",
    "        return torch.sum(\n",
    "            -0.5 * ((sample - mean)**2. * torch.exp(-logvar) + logvar + log2pi),\n",
    "            dim=raxis)\n",
    "    \n",
    "    def compute_loss(self, x):\n",
    "        mean, logvar = self.encode(x)\n",
    "\n",
    "        \n",
    "        z = self.reparameterize(mean, logvar)\n",
    "        x_logit = self.decode(z)\n",
    "        # print(x.shape, x_logit.shape, mean.shape, logvar.shape)\n",
    "        \n",
    "\n",
    "        cross_ent = nn.functional.binary_cross_entropy_with_logits(x_logit, x, reduction='none')\n",
    "        logpx_z = -torch.sum(cross_ent, dim=[1, 2, 3])\n",
    "        logpz = self.log_normal_pdf(z, 0., 0.)\n",
    "        logqz_x = self.log_normal_pdf(z, mean, logvar)\n",
    "        return -torch.mean(logpx_z + logpz - logqz_x)\n",
    "    \n",
    "    def train_step(self, x, e_optim, d_optim):\n",
    "        e_optim.zero_grad()\n",
    "        d_optim.zero_grad()\n",
    "        loss = self.compute_loss(x)\n",
    "        loss.backward()\n",
    "        e_optim.step()\n",
    "        d_optim.step()\n",
    "        return loss\n",
    "    \n",
    "    def train(self, dataLoader,\n",
    "              n_epochs = 100, sample_interval = 100,\n",
    "              save_interval = 5,\n",
    "              lr = 0.001, betas=(0.5, 0.9),\n",
    "              dumping_interval = 1000):\n",
    "        \n",
    "        losses = []\n",
    "        e_optim = torch.optim.Adam(self.encoder.parameters(), lr=lr, betas=betas)\n",
    "        d_optim = torch.optim.Adam(self.decoder.parameters(), lr=lr, betas=betas)\n",
    "        for epoch in range(n_epochs):\n",
    "            for idx, sample in enumerate(dataLoader):\n",
    "                imgs = sample[0]\n",
    "                real_imgs = imgs.to(self.device)\n",
    "                losses.append(self.train_step(real_imgs, e_optim, d_optim).item())\n",
    "                print(f'\\r[Epoch {epoch+1}/{n_epochs}] [Batch {(idx+1) % len(dataLoader)}/{len(dataLoader)}] [Loss: {losses[-1]:.3f}]\\t', end='')\n",
    "        plt.plot(losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VAE(40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 80])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(24154.9062, device='cuda:0', grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = np.random.normal(0, 1, (10, 1, 128, 128))\n",
    "z = torch.cuda.FloatTensor(z)\n",
    "gen_enc = model.encoder(z)\n",
    "print(gen_enc.shape)\n",
    "\n",
    "gen_loss = model.compute_loss(z)\n",
    "gen_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_img = model.decoder(gen_enc[:, :model.latent_dim]).detach().cpu().numpy()\n",
    "gen_img.shape\n",
    "\n",
    "plt.imshow(gen_img[0, 0, :, :])\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "plt.imshow(z[0, 0, :, :].detach().cpu().numpy())\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(n_epochs=10, dataLoader=train_dataLoader, lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "def sharpen_image(image, strength):\n",
    "    # Create a sharpening kernel\n",
    "    kernel = np.array([[-strength, -strength, -strength],\n",
    "                       [-strength, 1 + 8 * strength, -strength],\n",
    "                       [-strength, -strength, -strength]])\n",
    "    \n",
    "    # Apply the sharpening kernel to the image\n",
    "    sharpened_image = cv2.filter2D(image, -1, kernel)\n",
    "    \n",
    "    return sharpened_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch.normal(mean = 0., std=1.0, size=(BATCH_SIZE, model.latent_dim)).to(model.device)\n",
    "gen_img = model.decode(z, apply_sigmoid=False)[0, 0, :, :].detach().cpu().numpy()\n",
    "\n",
    "# gen_img = sharpen_image(gen_img, 0.03)\n",
    "\n",
    "plt.imshow(((gen_img)), cmap='Greys_r')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "# print(gen_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch.normal(mean = 0., std=1.0, size=(BATCH_SIZE, model.latent_dim)).to(model.device)\n",
    "gen_img = model.decode(z, apply_sigmoid=False)[0, 0, :, :].detach().cpu().numpy()\n",
    "\n",
    "# gen_img = sharpen_image(gen_img, 0.03)\n",
    "\n",
    "plt.imshow(((gen_img)), cmap='Greys_r')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "# print(gen_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_imgs = model.decode(z, apply_sigmoid=False)[:, 0, :, :].detach().cpu().numpy()\n",
    "\n",
    "for i in range(10):\n",
    "    plt.imshow(gen_imgs[i+50, :, :], cmap='Greys_r')\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_img = sharpen_image(gen_img, 0.01)\n",
    "plt.imshow(((gen_img)), cmap='Greys_r')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = next(iter(CIFAR_dataLoader))\n",
    "images = images[0, 0, :, :].detach().cpu().numpy()\n",
    "# images = sharpen_image(images, 0.03)\n",
    "print(images.shape)\n",
    "plt.imshow(images, cmap='Greys_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = sharpen_image(images, 0.03)\n",
    "print(images.shape)\n",
    "plt.imshow(images, cmap='Greys_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_imgs_2 = model.sample()[0, 0, :, :].detach().cpu().numpy()\n",
    "plt.imshow((gen_imgs_2), cmap='Greys_r')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_latent_images(model, n=5, epoch=10, im_size=128+2, save=False):\n",
    "    img_w = im_size * n\n",
    "    img_h = im_size * n\n",
    "\n",
    "    image = np.zeros((img_h, img_w))\n",
    "\n",
    "    norm = torch.distributions.Normal(0, 1)\n",
    "    grid_x = norm.icdf(torch.linspace(0.05, 0.95, n))\n",
    "    grid_y = norm.icdf(torch.linspace(0.05, 0.95, n))\n",
    "\n",
    "    # print(grid_x.shape)\n",
    "\n",
    "    for i, y_i in enumerate(grid_x):\n",
    "        for j, x_j in enumerate(grid_y):\n",
    "            z = torch.tensor([[x_j, y_i]])\n",
    "            z = torch.cat([z, torch.normal(0., 1., size=(1, (model.latent_dim-2)))], dim=1).to(device=model.device)\n",
    "            # print(z.shape)\n",
    "            x_decoded = model.decode(z=z, apply_sigmoid=True)\n",
    "\n",
    "            digit = x_decoded[0].view(im_size, im_size).detach().cpu().numpy()\n",
    "            # digit = np.pad(digit, ((1,1), (1,1)), mode='constant', constant_values=0)\n",
    "            # plt.imshow(digit)\n",
    "            # plt.show()\n",
    "\n",
    "            # digit = digit - np.min(digit)\n",
    "            # digit = digit / np.max(digit)\n",
    "\n",
    "            # print(np.max(digit), np.min(digit))\n",
    "\n",
    "            image[i * im_size:(i+1)*im_size, j*im_size:(j+1)*im_size] = digit\n",
    "\n",
    "    plt.imshow((image), cmap='Greys_r')\n",
    "    plt.axis('off')\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "plot_latent_images(model, n=10, im_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_latent_images(model, n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch.ones((1, model.latent_dim)).to(device=model.device)\n",
    "z[:, 0:5] = 0. \n",
    "print(z)\n",
    "img = model.decode(z)[0, 0, :, :].detach().cpu().numpy()\n",
    "plt.imshow(img, cmap='Greys_r')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(a)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
